{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/key.houck/Desktop/parts-ml-poc/data/at_service_job_AT_SJ_PART_AT_SO_PRODUCT_AT_SA_SERVICE_JOB_PRODUC_202402141028.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with any null values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling High Cardinality Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding for 'BRAND_NAME'\n",
    "brand_freq = data['BRAND_NAME'].value_counts().to_dict()\n",
    "data['brand_freq'] = data['BRAND_NAME'].map(brand_freq)\n",
    "\n",
    "# Frequency encoding for 'model_number'\n",
    "model_freq = data['MODEL_NUMBER'].value_counts().to_dict()\n",
    "data['model_freq'] = data['MODEL_NUMBER'].map(model_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Target Variable for Multi-Label Classification, Text Data Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# Clean text columns\n",
    "text_columns = ['DESCRIPTION', 'PROBLEM_DESCRIPTION', 'SERVICE_EXPLANATION']\n",
    "for col in text_columns:\n",
    "    data[col] = data[col].apply(clean_text)\n",
    "\n",
    "# Group and prepare the multi-label target variable\n",
    "grouped_parts = data.groupby('SERVICE_JOB_ID')['PART_NUMBER_ORDERED'].apply(lambda x: list(set(x))).reset_index()\n",
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot_labels = mlb.fit_transform(grouped_parts['PART_NUMBER_ORDERED'])\n",
    "\n",
    "# Ensure the grouped 'SERVICE_JOB_ID' is the same order as in 'data'\n",
    "data = data.set_index('SERVICE_JOB_ID').loc[grouped_parts['SERVICE_JOB_ID']].reset_index()\n",
    "\n",
    "# Now, vectorize the cleaned text columns\n",
    "tfidf_vectorizer_descr = TfidfVectorizer(max_features=1000)\n",
    "description_tfidf = tfidf_vectorizer_descr.fit_transform(data['DESCRIPTION'])\n",
    "\n",
    "tfidf_vectorizer_prob = TfidfVectorizer(max_features=1000)\n",
    "problem_description_tfidf = tfidf_vectorizer_prob.fit_transform(data['PROBLEM_DESCRIPTION'])\n",
    "\n",
    "tfidf_vectorizer_serv = TfidfVectorizer(max_features=1000)\n",
    "service_explanation_tfidf = tfidf_vectorizer_serv.fit_transform(data['SERVICE_EXPLANATION'])\n",
    "\n",
    "# Stack the TF-IDF matrices horizontally\n",
    "features = hstack([description_tfidf, problem_description_tfidf, service_explanation_tfidf])\n",
    "\n",
    "# Verify alignment between features and labels\n",
    "assert features.shape[0] == multi_hot_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (use the features DataFrame you prepared earlier)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, multi_hot_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MultiOutputClassifier with RandomForest\n",
    "multi_label_model = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
    "\n",
    "# Train the model\n",
    "multi_label_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
